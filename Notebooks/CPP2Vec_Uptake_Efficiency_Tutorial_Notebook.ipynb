{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b20717f5-5b7c-4ebf-9eed-bd048fc6561f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **CPP2Vec Uptake Efficiency Prediction Tutorial Notebook**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed7661c-a4c8-4171-89f8-834d37491a82",
   "metadata": {},
   "source": [
    "### Load all necessary libraries and the pre-trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dafec8-c9a2-4237-a281-08f6855b391a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "import pickle\n",
    "\n",
    "# Load CPP2Vec's pretrained models\n",
    "\n",
    "# Word2Vec model\n",
    "w2v = Word2Vec.load(\"W2V_Uptake-Efficiency.pt\")\n",
    "\n",
    "# ML model\n",
    "with open(\"ML_Uptake-Efficiency.asv\", \"rb\") as f:\n",
    "    ml_model = pickle.load(f)\n",
    "\n",
    "print(\"\\nWord2Vec and Machine Learning models loaded successfully!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481fee22-d597-494e-803a-3b8227d10dc0",
   "metadata": {},
   "source": [
    "### Define functions to process peptide sequences, generate embeddings and calculate evaluation metrics for CPP prediction.\n",
    "\n",
    "1. pad_sequences: Pads or truncates sequences to fixed length (seqwin)\n",
    "2. sep_word: Splits sequences into overlapping k-mers\n",
    "3. emb_seq_w2v: Converts sequences into numeric vectors using Word2Vec\n",
    "4. evaluate_metrics: Computes Sensitivity, Specificity, Accuracy, AUC, MCC, F1-Score, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ba6ba9-1c97-4827-8d3f-02afd8227f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(seq_list, seqwin=61):\n",
    "    padded = []\n",
    "    for seq in seq_list:\n",
    "        seq = seq.strip()\n",
    "        if len(seq) > seqwin:\n",
    "            seq = seq[:seqwin]\n",
    "        padded.append(seq.ljust(seqwin, \"X\"))\n",
    "    return padded\n",
    "\n",
    "def sep_word(sequences, k=2):\n",
    "    return [[seq[i:i+k] for i in range(len(seq)-k+1)] for seq in sequences]\n",
    "\n",
    "def emb_seq_w2v(seq_list, w2v_model, k=2):\n",
    "    num_seq = len(seq_list)\n",
    "    for j, seq in enumerate(seq_list):\n",
    "        enc = np.array([w2v_model.wv[seq[i:i+k]] for i in range(len(seq)-k+1)])\n",
    "        if j == 0:\n",
    "            seq_emb = enc\n",
    "        else:\n",
    "            seq_emb = np.append(seq_emb, enc, axis=0)\n",
    "    seq_emb = seq_emb.reshape(num_seq, -1)\n",
    "    return seq_emb\n",
    "\n",
    "def evaluate_metrics(y_true, y_prob, threshold=0.5):\n",
    "    y_pred = (y_prob >= threshold).astype(int)\n",
    "\n",
    "    tp = ((y_true==1) & (y_pred==1)).sum()\n",
    "    tn = ((y_true==0) & (y_pred==0)).sum()\n",
    "    fp = ((y_true==0) & (y_pred==1)).sum()\n",
    "    fn = ((y_true==1) & (y_pred==0)).sum()\n",
    "\n",
    "    sensitivity = tp / (tp + fn) if (tp+fn)>0 else 0\n",
    "    specificity = tn / (tn + fp) if (tn+fp)>0 else 0\n",
    "    mcc = ((tp*tn - fp*fn) / \n",
    "           np.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n",
    "          ) if (tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)>0 else 0\n",
    "\n",
    "    return {\n",
    "        \"Sensitivity\": sensitivity,\n",
    "        \"Specificity\": specificity,\n",
    "        \"Accuracy\": metrics.accuracy_score(y_true, y_pred),\n",
    "        \"AUC\": metrics.roc_auc_score(y_true, y_prob),\n",
    "        \"MCC\": mcc,\n",
    "        \"Precision\": metrics.precision_score(y_true, y_pred),\n",
    "        \"Recall\": metrics.recall_score(y_true, y_pred),\n",
    "        \"F1-Score\": metrics.f1_score(y_true, y_pred),\n",
    "        \"AUPRC\": metrics.average_precision_score(y_true, y_prob)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4851f6-6feb-4420-9daa-59bb945cfae6",
   "metadata": {},
   "source": [
    "### Load Sequences to be Predicted from a TXT File.\n",
    "\n",
    "**Acceptable input formats:**\n",
    "\n",
    "| Format | Example | Notes |\n",
    "|--------|---------|-------|\n",
    "| **Sequences only** (no labels) | RRRRRRRGGIYLATALAKWALKQ<br>IYLATALAKWALKQGGRRRRRRR<br>KLAKLAKKLAKLAKGGRRRRRRR<br>SHMMGEFWGDEDMCYRHQRSYET | Each line contains a single peptide sequence. Metrics cannot be calculated without labels. Predictions only. |\n",
    "| **Sequences with labels** | RRRRRRRGGIYLATALAKWALKQ,1<br>KLAKLAKKLAKLAKGGRRRRRRR,1<br>FQAYPCITAYKVMYID,0<br>SHMMGEFWGDEDMCYRHQRSYET,0 | Each line contains a sequence and a true label separated by a comma. Metrics will be calculated automatically. |\n",
    "<br>\n",
    "**Labels: 1 = High, 0 = Low**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87889ad3-2b97-41d1-a3b3-6566ba811661",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"CPP_Uptake_Input.txt\" \n",
    "\n",
    "# Read sequences (and optional labels)\n",
    "seqs = []\n",
    "true_labels = []\n",
    "\n",
    "with open(input_file, \"r\") as f:\n",
    "    lines = f.read().strip().split(\"\\n\")\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        parts = line.split(\",\")\n",
    "        seqs.append(parts[0].strip())\n",
    "        if len(parts) > 1:\n",
    "            true_labels.append(int(parts[1].strip()))\n",
    "\n",
    "print(f\"{len(seqs)} sequences loaded from {input_file}.\")\n",
    "if true_labels:\n",
    "    print(\"Labels detected for metrics calculation.\")\n",
    "\n",
    "print(\"\\nA preview of the first 5 sequences:\\n\")    \n",
    "seqs[:5] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072bcb3a-fbd1-48c7-a6c8-2d483eda048b",
   "metadata": {},
   "source": [
    "### Preprocess sequences, generate embeddings, apply PCA, predict with SVM, and save results to CSV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309098de-095d-4032-b265-ba2f8392ca5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqwin = 61\n",
    "kmer = 3\n",
    "\n",
    "# Pad sequences\n",
    "padded = pad_sequences(seqs, seqwin)\n",
    "\n",
    "# Generate embeddings using Word2Vec\n",
    "embedded = emb_seq_w2v(padded, w2v, kmer)\n",
    "\n",
    "# Predict probabilities using SVM\n",
    "prob = ml_model.predict_proba(embedded)[:, 1]\n",
    "\n",
    "# Convert probabilities to labels\n",
    "pred_labels = [\"High\" if p >= 0.5 else \"Low\" for p in prob]\n",
    "\n",
    "# Results table\n",
    "df_results = pd.DataFrame({\n",
    "    \"Sequence\": seqs,\n",
    "    \"Predicted_Label\": pred_labels,\n",
    "    \"Probability\": prob\n",
    "})\n",
    "\n",
    "print(df_results)\n",
    "\n",
    "# Save to CSV\n",
    "output_file = \"CPP2Vec_Uptake_Predictions.csv\"\n",
    "df_results.to_csv(output_file, index=False)\n",
    "print(f\"\\nPredictions saved to '{output_file}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6547bf8e-84aa-454c-8855-1cc288680ff8",
   "metadata": {},
   "source": [
    "### If true labels are provided in the TXT file, evaluation metrics are calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206a6470-9496-4841-ae40-05e39a4358af",
   "metadata": {},
   "outputs": [],
   "source": [
    "if true_labels:\n",
    "    from sklearn import metrics\n",
    "\n",
    "    y_true = np.array(true_labels)\n",
    "    y_prob = prob\n",
    "    y_pred = np.array([1 if p >= 0.5 else 0 for p in y_prob])\n",
    "\n",
    "    tp = ((y_true==1) & (y_pred==1)).sum()\n",
    "    tn = ((y_true==0) & (y_pred==0)).sum()\n",
    "    fp = ((y_true==0) & (y_pred==1)).sum()\n",
    "    fn = ((y_true==1) & (y_pred==0)).sum()\n",
    "    mcc = ((tp*tn - fp*fn) / np.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))) \\\n",
    "          if (tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)>0 else 0\n",
    "\n",
    "    metrics_res = {\n",
    "        \"Sensitivity\": tp / (tp+fn) if (tp+fn)>0 else 0,\n",
    "        \"Specificity\": tn / (tn+fp) if (tn+fp)>0 else 0,\n",
    "        \"Accuracy\": metrics.accuracy_score(y_true, y_pred),\n",
    "        \"AUC\": metrics.roc_auc_score(y_true, y_prob),\n",
    "        \"MCC\": mcc,\n",
    "        \"Precision\": metrics.precision_score(y_true, y_pred),\n",
    "        \"Recall\": metrics.recall_score(y_true, y_pred),\n",
    "        \"F1-Score\": metrics.f1_score(y_true, y_pred),\n",
    "        \"AUPRC\": metrics.average_precision_score(y_true, y_prob)\n",
    "    }\n",
    "\n",
    "    print(\"~~~ Evaluation Metrics ~~~\\n\")\n",
    "    for k, v in metrics_res.items():\n",
    "        print(f\"{k}: {v:.4f}\")\n",
    "else:\n",
    "    print(\"No true labels provided. Metrics calculation skipped.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (CPP2Vec)",
   "language": "python",
   "name": "cpp2vec_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
